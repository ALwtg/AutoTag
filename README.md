# 🎥 AI AutoTag: 多模态视频追踪与智能标注平台

**AutoTag** 是一个基于 Web 的轻量级、交互式标注平台。它利用先进的多模态大模型（如 Gemini、GLM、Qwen-VL）对图片进行精准标注，并对视频中的物体进行跨帧追踪与平滑渲染。

---

## ✨ 核心特性

- **✨ 更舒服的UI**
  - **UI展示**：
  <img width="2559" height="1356" alt="image" src="https://github.com/user-attachments/assets/42d1b299-2c5b-429c-a778-17f95c6e82ba" />
  - **做到一半要断网了？**
  - 支持自动备份和手动备份任务，下次可以直接从断点开始，零帧起手

- **🚀 双模式交互**
  - **图片标注模式**：上传图片并描述目标，AI 自动返回带标签的坐标框。  
  - <img width="1720" height="1170" alt="image" src="https://github.com/user-attachments/assets/f4eaab4f-8c11-4dda-b5b1-1f8e4abb06f1" />
  - 你甚至可以这么做，后期想改进成类似目前很火的”豆包手机“的效果，成为你的手机助手：<img width="1752" height="1302" alt="image" src="https://github.com/user-attachments/assets/36e20b3c-de3d-4122-9a3a-9a01d863f053" />

  - **视频追踪模式**：支持对视频中的特定物体进行连续追踪，自动生成移动轨迹。
  - 

https://github.com/user-attachments/assets/969acf19-a268-4646-8899-296dc613f52a
  - 在多物体追踪和遮挡也表现出较好的性能：
  - 

https://github.com/user-attachments/assets/a0bb5f5c-3e02-4dff-aa08-8763db96cf2f



- **🧠 强大的模型集成**
  - 内置支持 **Gemini 3 Flash**, **GLM-4.6V**, **Qwen-VL** 等顶级多模态模型。经过测试，Gemini 3 Flash表现最佳，Qwen-VL排第二
  - 通过 API 接口按需切换模型，兼顾速度与识别精度。
- **🕒 智能插值算法**
  - 采用 **线性插值 (Linear Interpolation)** 技术。即使 AI 只识别了少量的关键帧，系统也能自动计算中间帧的坐标，实现顺滑的 60FPS 追踪动画。
- **🎞️ 帧级控制与并发处理**
  - 支持**手动抽帧模式**，可调节 FPS（每秒帧数）和并行请求数，极大提升视频处理效率。建议抽帧频率 (5帧/秒)，并行请求数 5并发。能在token消耗量较少的条件下达到比较好的效果
- **📥 多格式导出**
  - 实时渲染 Canvas 覆盖层。
  - 支持将处理后的结果导出为 **.mp4 视频**（含标注层）或高质量标注图片。
- **🎨 极简 UI 设计**
  - 基于 Tailwind CSS 构建，支持响应式布局，提供实时处理进度条和结果时间轴。

---

## 🛠️ 技术深度

- **Canvas 实时渲染**：使用双层 Canvas 架构，底层播放视频，顶层由算法驱动实时同步绘制标注框。
- **录制引擎**：集成 `MediaRecorder API`，实现在浏览器前端完成视频流的实时合成与导出，无需后端参与。
- **归一化坐标处理**：使用 0-1000 的归一化坐标系，确保标注结果在不同分辨率的显示器上保持一致。
- **支持yolo格式输出**：<img width="2560" height="1530" alt="image" src="https://github.com/user-attachments/assets/28c1d411-91e4-431b-a71c-cc33a485195b" />
<img width="2560" height="1530" alt="image" src="https://github.com/user-attachments/assets/bf49ca3f-3ac8-4205-8e72-27bac293220f" />



---

## 🚀 快速开始

1. **获取代码**
   下载 `Web/` 文件或者直接在版本更新中选择最新版本下载压缩包文件。
2. **环境准备**
   由于是纯前端项目，你只需要一个浏览器（Chrome / Edge / Safari）。
3. **配置 API (可选)**
   在源码中的 `CONFIGS.js` 常量中填入你自己的 API Key，目前只支持OpenAI兼容格式。
4. **运行**
   双击 `AutoTag.html` 即可在浏览器中运行。

---

## 📖 使用指南

1. **选择模式**：点击顶部的“模式切换”开关，选择图片或视频模式。
2. **上传文件**：点击上传区域，选择你需要处理的素材。
3. **输入指令**：在指令框输入你想标注或追踪的对象（例如：“追踪视频中那辆红色的汽车”）。
4. **开始分析**：点击“开始分析”，AI 将分批处理帧数据，你可以在下方看到实时进度。
5. **交互与导出**：
   - 视频模式下，点击右侧生成的“时间轴”可快速跳转到对应帧。
   - 点击“下载结果”保存你的作品。

---

## 💰 单次成本与价格预估 

- **示例gemini-3-flash API 价格**：
- （实际价格会有所浮动）
- • 输入：0.002 CA/1K Tokens
- • 输出：0.012 CA/1K Tokens
- 请求一次平均
- 问题Tokens: 1176
- 回答Tokens: 307
- 总消耗Tokens: 1483
- 扣费大约： 0.006元

---

## ⚠️ 注意事项

- **API 额度**：本工具依赖外部模型 API，频繁处理长视频可能会消耗较多 Token。
- **跨域限制**：若使用外部视频 URL，需确保对方服务器支持 CORS 跨域请求。
- **浏览器性能**：视频导出过程通过前端录制，录制期间请勿切换标签页。

---



*注：精度取决于模型聪明度  
*作者：一只小白虎_晓枫呀*
